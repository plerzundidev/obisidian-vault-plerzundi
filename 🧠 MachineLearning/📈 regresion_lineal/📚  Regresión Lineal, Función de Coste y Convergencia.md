

## 1. Conceptos Fundamentales

### 1.1 **Regresi贸n Lineal**

Es un modelo que busca encontrar una **recta** (o hiper plano en dimensiones superiores) que mejor se ajuste a los datos. La f贸rmula general es:

$$y = a + b \cdot x$$

- **`a`**: Intercepto (valor de `y` cuando `x = 0`).
- **`b`**: Pendiente (cambio en `y` por unidad de `x`).

Para m煤ltiples variables, la f贸rmula se expande a:

$$y = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + ... + \theta_n x_n$$

Que puede escribirse de forma matricial como:

$$y = \theta^T X$$

---

### 1.2 **Funci贸n de Coste (MSE - Error Cuadr谩tico Medio)**

Mide el error promedio entre las predicciones del modelo (`欧`) y los valores reales (`y`).

#### **Versi贸n 1: Con `1/(2m)`**

$$J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (欧_i - y_i)^2$$

- **Derivadas**:

$$\frac{\partial J}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m} (欧_i - y_i) \cdot x_{ij}$$

(Donde $x_{i0} = 1$ para el t茅rmino independiente)

#### **Versi贸n 2: Con `1/m`**

$$J(\theta) = \frac{1}{m} \sum_{i=1}^{m} (欧_i - y_i)^2$$

- **Derivadas**:

$$\frac{\partial J}{\partial \theta_j} = \frac{2}{m} \sum_{i=1}^{m} (欧_i - y_i) \cdot x_{ij}$$

> **Nota**: El factor 1/2 en la primera versi贸n se usa para simplificar la derivada, eliminando el factor 2 que surge al derivar el t茅rmino cuadr谩tico.

---

### 1.3 **Convergencia con Gradiente Descendiente**

Proceso iterativo para ajustar los par谩metros $\theta$ minimizando el coste:

#### **Actualizaci贸n de Par谩metros**:

$$\theta_j^{\text{nuevo}} = \theta_j^{\text{antiguo}} - \alpha \cdot \frac{\partial J}{\partial \theta_j}$$

- **`伪`**: Tasa de aprendizaje.

**Visualizaci贸n del Gradiente Descendiente:**

- La funci贸n de coste forma una superficie en el espacio
- Cada punto representa una combinaci贸n de par谩metros
- El algoritmo "desciende" hacia el punto m谩s bajo (m铆nimo)

#### **Tipos de Gradiente Descendiente**:

1. **Batch Gradient Descent**: Usa todos los datos para cada actualizaci贸n
2. **Stochastic Gradient Descent (SGD)**: Usa un solo dato para cada actualizaci贸n
3. **Mini-Batch Gradient Descent**: Usa un subconjunto de datos para cada actualizaci贸n

---

## 2. Caso de Negocio: Predecir Ventas de Helados 

### **2.1 Datos Hist贸ricos**

|Temperatura (掳C)|Ventas (helados)|
|---|---|
|20|50|
|25|80|
|30|120|
|15|40|
|35|150|

---

### **2.2 Definir el Modelo Inicial**

Valores iniciales:

$$a = 10, \quad b = 3$$

Predicciones iniciales:

- Para 20掳C: $欧 = 10 + 3 \cdot 20 = 70$ (Error: 70 - 50 = 20)
- Para 25掳C: $欧 = 10 + 3 \cdot 25 = 85$ (Error: 85 - 80 = 5)
- Para 30掳C: $欧 = 10 + 3 \cdot 30 = 100$ (Error: 100 - 120 = -20)
- Para 15掳C: $欧 = 10 + 3 \cdot 15 = 55$ (Error: 55 - 40 = 15)
- Para 35掳C: $欧 = 10 + 3 \cdot 35 = 115$ (Error: 115 - 150 = -35)

---

### **2.3 Calcular el Coste (Versi贸n `1/(2m)`)**

$$J(10, 3) = \frac{1}{2 \cdot 5} \left[(70-50)^2 + (85-80)^2 + (100-120)^2 + (55-40)^2 + (115-150)^2 \right]$$ $$= \frac{1}{10} \left[400 + 25 + 400 + 225 + 1225 \right]$$ $$= \frac{2275}{10} = 227.5$$

---

### **2.4 Calcular Derivadas Parciales (Versi贸n `1/(2m)`)**

- **Derivada respecto a `a`**:

$$\frac{\partial J}{\partial a} = \frac{1}{5} \left[(70-50) + (85-80) + (100-120) + (55-40) + (115-150) \right]$$ $$= \frac{1}{5} \left[20 + 5 + (-20) + 15 + (-35) \right]$$ $$= \frac{1}{5} \cdot (-15) = -3$$

- **Derivada respecto a `b`** (corregida):

$$\frac{\partial J}{\partial b} = \frac{1}{5} \left[(70-50) \cdot 20 + (85-80) \cdot 25 + (100-120) \cdot 30 + (55-40) \cdot 15 + (115-150) \cdot 35 \right]$$ $$= \frac{1}{5} \left[20 \cdot 20 + 5 \cdot 25 + (-20) \cdot 30 + 15 \cdot 15 + (-35) \cdot 35 \right]$$ $$= \frac{1}{5} \left[400 + 125 - 600 + 225 - 1225 \right]$$ $$= \frac{1}{5} \cdot (-1075) = -215$$

---

### **2.5 Ajustar Par谩metros**

Con tasa de aprendizaje `伪 = 0.01`:

$$a_{\text{nuevo}} = 10 - 0.01 \cdot (-3) = 10 + 0.03 = 10.03$$  
$$b_{\text{nuevo}} = 3 - 0.01 \cdot (-215) = 3 + 2.15 = 5.15$$

---

### **2.6 Segunda Iteraci贸n (Demostrativa)**

Con los nuevos par谩metros $a = 10.03, b = 5.15$:

Predicciones actualizadas:

- Para 20掳C: $欧 = 10.03 + 5.15 \cdot 20 = 113.03$ (Error: 113.03 - 50 = 63.03)
- Para 25掳C: $欧 = 10.03 + 5.15 \cdot 25 = 138.78$ (Error: 138.78 - 80 = 58.78)
- Para 30掳C: $欧 = 10.03 + 5.15 \cdot 30 = 164.53$ (Error: 164.53 - 120 = 44.53)
- Para 15掳C: $欧 = 10.03 + 5.15 \cdot 15 = 87.28$ (Error: 87.28 - 40 = 47.28)
- Para 35掳C: $欧 = 10.03 + 5.15 \cdot 35 = 190.28$ (Error: 190.28 - 150 = 40.28)

Coste actualizado:

$$J(10.03, 5.15) = \frac{1}{10} \left[63.03^2 + 58.78^2 + 44.53^2 + 47.28^2 + 40.28^2 \right]$$ $$= \frac{1}{10} \cdot 13662.39 = 1366.24$$

> Observaci贸n: El coste aument贸 de 227.5 a 1366.24. Esto significa que necesitamos ajustar la tasa de aprendizaje, ya que es demasiado grande y nos est谩 haciendo "saltar" demasiado lejos.

---

### **2.7 Convergencia con Tasa de Aprendizaje Ajustada**

Con una tasa de aprendizaje menor, por ejemplo `伪 = 0.001`:

$$a_{\text{nuevo}} = 10 - 0.001 \cdot (-3) = 10.003$$  
$$b_{\text{nuevo}} = 3 - 0.001 \cdot (-215) = 3.215$$

Despu茅s de m煤ltiples iteraciones (alrededor de 10,000 con `伪 = 0.001`), los par谩metros convergen aproximadamente a:

$$a \approx -12.2, \quad b \approx 4.7$$

**Modelo Final**:

$$欧 = -12.2 + 4.7 \cdot x$$

- **Predicci贸n para 28掳C**:

$$欧 = -12.2 + 4.7 \cdot 28 \approx 119.4 \text{ helados}$$

---

## 3. Implementaci贸n en Python

```python
import numpy as np
import matplotlib.pyplot as plt

# Datos de ejemplo
X = np.array([20, 25, 30, 15, 35])  # Temperatura
y = np.array([50, 80, 120, 40, 150])  # Ventas

# Par谩metros iniciales
a = 10
b = 3
alpha = 0.0001  # Tasa de aprendizaje
iterations = 50000

# Historiales para visualizaci贸n
cost_history = []
a_history = []
b_history = []

# Gradiente descendiente
for i in range(iterations):
    # C谩lculo de predicciones
    y_pred = a + b * X
    
    # C谩lculo del coste
    cost = (1/(2*len(X))) * np.sum((y_pred - y)**2)
    cost_history.append(cost)
    
    # C谩lculo de derivadas
    da = (1/len(X)) * np.sum(y_pred - y)
    db = (1/len(X)) * np.sum((y_pred - y) * X)
    
    # Actualizaci贸n de par谩metros
    a = a - alpha * da
    b = b - alpha * db
    
    # Guardar historiales
    a_history.append(a)
    b_history.append(b)

print(f"Par谩metros finales: a = {a:.2f}, b = {b:.2f}")
print(f"Coste final: {cost_history[-1]:.2f}")
```

---

## 4. Visualizaci贸n del Proceso de Convergencia

### 4.1 **Evoluci贸n del Coste**

La evoluci贸n del coste t铆picamente muestra:

- Disminuci贸n r谩pida al principio
- Desaceleraci贸n gradual
- Estabilizaci贸n cuando se acerca al m铆nimo

### 4.2 **Evoluci贸n de los Par谩metros**

Los par谩metros suelen:

- Cambiar r谩pidamente al principio
- Luego ajustarse m谩s finamente
- Eventualmente estabilizarse cuando el modelo converge

### 4.3 **Ajuste del Modelo Final**

Un buen ajuste del modelo final deber铆a:

- Pasar cerca de la mayor铆a de los puntos
- No estar sesgado hacia ninguna regi贸n espec铆fica de los datos
- Capturar la tendencia general sin sobreajustarse a puntos espec铆ficos

---

## 5. Regresi贸n Lineal M煤ltiple: Ampliando el Modelo

La regresi贸n lineal m煤ltiple extiende el concepto a m煤ltiples variables predictoras:

$$y = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + ... + \theta_n x_n$$

### 5.1 **Ejemplo: Predecir Precios de Casas**

Variables predictoras:

- Tama帽o (m虏)
- N煤mero de habitaciones
- Antig眉edad (a帽os)

|Tama帽o|Habitaciones|Antig眉edad|Precio (miles $)|
|---|---|---|---|
|100|2|15|150|
|120|3|10|180|
|150|3|5|220|
|80|1|20|120|
|200|4|2|300|

El modelo ser谩:

$$\text{Precio} = \theta_0 + \theta_1 \cdot \text{Tama帽o} + \theta_2 \cdot \text{Habitaciones} + \theta_3 \cdot \text{Antig眉edad}$$

### 5.2 **Implementaci贸n del Ejemplo en Python**

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Datos
data = {
    'Tama帽o': [100, 120, 150, 80, 200],
    'Habitaciones': [2, 3, 3, 1, 4],
    'Antig眉edad': [15, 10, 5, 20, 2],
    'Precio': [150, 180, 220, 120, 300]
}

df = pd.DataFrame(data)

# Caracter铆sticas y target
X = df[['Tama帽o', 'Habitaciones', 'Antig眉edad']]
y = df['Precio']

# Dividir en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo
model = LinearRegression()
model.fit(X_train, y_train)

# Coeficientes y t茅rmino independiente
print(f"T茅rmino independiente (胃): {model.intercept_:.2f}")
print("Coeficientes:")
for feature, coef in zip(X.columns, model.coef_):
    print(f"  {feature}: {coef:.2f}")

# Predicciones
y_pred = model.predict(X_test)

# Evaluaci贸n
print(f"Error cuadr谩tico medio: {mean_squared_error(y_test, y_pred):.2f}")
print(f"Coeficiente de determinaci贸n (R虏): {r2_score(y_test, y_pred):.2f}")
```

---

## 6. Problemas Comunes y Soluciones

### 6.1 **Overfitting (Sobreajuste)**

Cuando el modelo se ajusta demasiado a los datos de entrenamiento y no generaliza bien.

**Soluciones:**

- Regularizaci贸n (Ridge, Lasso)
- M谩s datos de entrenamiento
- Reducir complejidad del modelo

### 6.2 **Underfitting (Subajuste)**

Cuando el modelo es demasiado simple y no captura la estructura de los datos.

**Soluciones:**

- Aumentar complejidad del modelo
- Incluir m谩s caracter铆sticas
- Feature engineering

### 6.3 **Alta Multicolinealidad**

Cuando hay alta correlaci贸n entre caracter铆sticas.

**Soluciones:**

- An谩lisis de componentes principales (PCA)
- Eliminar caracter铆sticas redundantes
- Regularizaci贸n Ridge

### 6.4 **Escala de Caracter铆sticas**

Cuando las caracter铆sticas tienen diferentes escalas.

**Soluciones:**

- Normalizaci贸n (Min-Max)
- Estandarizaci贸n (Z-score)

---

## 7. Regularizaci贸n para Regresi贸n Lineal

### 7.1 **Ridge Regression (L2)**

A帽ade penalizaci贸n por la suma de cuadrados de coeficientes:

$$J(\theta) = MSE + \lambda \sum_{j=1}^{n} \theta_j^2$$

### 7.2 **Lasso Regression (L1)**

A帽ade penalizaci贸n por la suma de valores absolutos de coeficientes:

$$J(\theta) = MSE + \lambda \sum_{j=1}^{n} |\theta_j|$$

### 7.3 **Implementaci贸n de Ridge en Python**

```python
from sklearn.linear_model import Ridge

# Crear y entrenar el modelo con regularizaci贸n Ridge
ridge_model = Ridge(alpha=1.0)  # alpha es el par谩metro de regularizaci贸n 位
ridge_model.fit(X_train, y_train)

# Coeficientes
print("Coeficientes con Ridge:")
for feature, coef in zip(X.columns, ridge_model.coef_):
    print(f"  {feature}: {coef:.2f}")
```

---

## 8. Interpretaci贸n de Resultados

### 8.1 **Coeficientes**

Cada coeficiente representa el cambio esperado en la variable objetivo por unidad de cambio en la caracter铆stica correspondiente, manteniendo constantes las dem谩s caracter铆sticas.

### 8.2 **Intercepto**

Representa el valor esperado de la variable objetivo cuando todas las caracter铆sticas son cero.

### 8.3 **R虏 (Coeficiente de Determinaci贸n)**

Mide la proporci贸n de la varianza total de la variable objetivo que es explicada por el modelo.

- **R虏 = 1**: El modelo explica perfectamente la variaci贸n.
- **R虏 = 0**: El modelo no explica nada de la variaci贸n.
- **R虏 < 0**: El modelo es peor que simplemente usar la media.

---

## 9. Evaluaci贸n y Validaci贸n del Modelo

### 9.1 **T茅cnicas de Validaci贸n**

- Validaci贸n cruzada (k-folds)
- Train/Test Split
- Leave-One-Out Cross-Validation
- Validaci贸n cronol贸gica (para series temporales)

### 9.2 **M茅tricas de Evaluaci贸n**

- Error Cuadr谩tico Medio (MSE)
- Ra铆z del Error Cuadr谩tico Medio (RMSE)
- Error Absoluto Medio (MAE)
- Coeficiente de Determinaci贸n (R虏)

---

## 10. Resumen de F贸rmulas

| **Concepto**         | **F贸rmula (`1/(2m)`)**                  | **F贸rmula (`1/m`)**                     |
| -------------------- | --------------------------------------- | --------------------------------------- |
| **Funci贸n de Coste** | $$J = \frac{1}{2m} \sum (欧_i - y_i)^2$$ | $$J = \frac{1}{m} \sum (欧_i - y_i)^2$$  |
| **Derivada de `胃j`** | $$\frac{1}{m} \sum (欧_i - y_i) x_{ij}$$ | $$\frac{2}{m} \sum (欧_i - y_i) x_{ij}$$ |
| **Ridge (L2)**       | $$J + \lambda \sum \theta_j^2$$         | $$J + \lambda \sum \theta_j^2$$         |
| **Lasso (L1)**       | $$J + \lambda \sum$$                    | $$\theta_j$$                            |

---

## 11. Consideraciones Pr谩cticas

1. **Preparaci贸n de datos**:
    
    - Manejo de valores faltantes
    - Detecci贸n y tratamiento de outliers
    - Codificaci贸n de variables categ贸ricas
2. **Selecci贸n de caracter铆sticas**:
    
    - Feature importance
    - Forward/Backward selection
    - T茅cnicas de reducci贸n de dimensionalidad
3. **Hiperpar谩metros importantes**:
    
    - Tasa de aprendizaje (伪)
    - Par谩metro de regularizaci贸n (位)
    - N煤mero de iteraciones
4. **Herramientas y librer铆as**:
    
    - Scikit-learn (Python)
    - StatsModels (Python)
    - R (lm, glmnet)
    - TensorFlow y PyTorch para modelos m谩s complejos

---

## 12. Notas Finales

1. **Coherencia en las f贸rmulas**:
    
    - `1/(2m)` siempre est谩 en la **funci贸n de coste**, y las derivadas usan `1/m`.
    - `1/m` en la funci贸n de coste implica derivadas con `2/m`.
2. **Tasa de aprendizaje (`伪`)**:
    
    - Si usas `1/m`, reduce `伪` a la mitad para compensar el factor `2` en las derivadas.
    - Una tasa de aprendizaje demasiado grande puede causar divergencia
    - Una tasa demasiado peque帽a puede hacer que la convergencia sea muy lenta
    -
3. **Regresi贸n lineal vs. otros algoritmos**:
    
    - Ventajas: Interpretabilidad, rapidez, base para modelos complejos
    - Desventajas: Asume relaci贸n lineal, sensible a outliers

---

## 13. Ejemplo Gr谩fico: Convergencia del Modelo de Helados

### Modelo Inicial vs. Final

Imaginemos una visualizaci贸n de nuestro modelo de ventas de helados:

**Modelo Inicial (a=10, b=3)**:

- Predicciones alejadas de los valores reales
- Error total alto (MSE = 227.5)

**Modelo Final (a=-12.2, b=4.7)**:

- Predicciones muy cercanas a los valores reales
- Error total m铆nimo
- Captura bien la relaci贸n temperatura-ventas

### Proceso de Convergencia

Durante el entrenamiento observar铆amos:

1. El modelo inicial empieza lejos de los datos
2. Con cada iteraci贸n, la l铆nea se acerca a los puntos
3. La pendiente aumenta desde 3 hasta 4.7
4. El intercepto disminuye desde 10 hasta -12.2
5. El error (MSE) disminuye progresivamente
6. Eventualmente el modelo "converge" y se estabiliza

---

## 14. Aplicaciones Pr谩cticas en Machine Learning

### Predicci贸n de Ventas

- Predecir ventas basadas en gastos de publicidad
- Variables: presupuesto en TV, radio, peri贸dicos, etc.
- Objetivo: optimizar distribuci贸n de presupuesto

### Predicci贸n de Precios

- Predecir precios de viviendas, acciones, productos
- Variables: caracter铆sticas, hist贸ricos, tendencias
- Objetivo: decisiones de inversi贸n o fijaci贸n de precios

### An谩lisis de Influencia

- Determinar qu茅 variables impactan m谩s un resultado
- Variables: cualquier factor medible
- Objetivo: toma de decisiones estrat茅gicas
