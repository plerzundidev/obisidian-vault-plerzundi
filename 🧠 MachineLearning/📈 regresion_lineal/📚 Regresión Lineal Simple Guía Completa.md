

La **regresi√≥n lineal simple** es un algoritmo de machine learning que modela la relaci√≥n lineal entre una variable independiente ($x$) y una variable dependiente ($y$). Su objetivo es encontrar una recta que minimice el error entre las predicciones y los valores reales.

**Ecuaci√≥n del modelo:**  
$$ h_\theta(x) = \theta_0 + \theta_1 x $$  
- $h_\theta(x)$: Predicci√≥n de $y$.  
- $\theta_0$: Intercepto (valor de $y$ cuando $x=0$).  
- $\theta_1$: Pendiente (cambio en $y$ por unidad de $x$).  

---

## üìú **S√≠mbolos Clave**

| **S√≠mbolo** | **Significado** | **Ejemplo** |
|-------------|-----------------|-------------|
| $x^{(i)}$   | Variable independiente | Tama√±o de una casa (m¬≤) |
| $y^{(i)}$   | Variable dependiente | Precio de la casa (\$) |
| $\theta_0$  | Intercepto | Costo base de una casa ($x=0$) |
| $\theta_1$  | Pendiente | Aumento en precio por m¬≤ |
| $J(\theta_0, \theta_1)$ | Funci√≥n de costo | Error cuadr√°tico medio |
| $\alpha$    | Tasa de aprendizaje | Velocidad de ajuste (ej: $0.01$) |
| $\frac{\partial}{\partial \theta_j} J$ | Derivada parcial | Direcci√≥n para reducir el error |

---

## üßÆ **Funci√≥n de Costo (Error)**

Mide el error promedio entre las predicciones y los valores reales:  
$$ J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2 $$  
- $m$: N√∫mero de ejemplos de entrenamiento.  
- **Ejemplo:** Si $\theta_0 = 0$, $\theta_1 = 1$, y los datos son $(1,1), (2,2), (3,3)$:  
  $$ J = \frac{1}{6} \left[ (1-1)^2 + (2-2)^2 + (3-3)^2 \right] = 0 $$

---

## üîÑ **Gradiente Descendente**
Algoritmo para minimizar $J(\theta_0, \theta_1)$. Actualiza $\theta_0$ y $\theta_1$ iterativamente.

### **F√≥rmulas de Actualizaci√≥n**  
$$ \theta_j := \theta_j - \alpha \cdot \frac{\partial}{\partial \theta_j} J $$  

### **Derivadas Parciales**  
- Para $\theta_0$:  
  $$ \frac{\partial}{\partial \theta_0} J = \frac{1}{m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) $$  
- Para $\theta_1$:  
  $$ \frac{\partial}{\partial \theta_1} J = \frac{1}{m} \sum_{i=1}^m \left( h_\theta(x^{(i)}) - y^{(i)} \right) x^{(i)} $$  

---

## üõ†Ô∏è **Ejemplo Pr√°ctico: Predicci√≥n de Precios de Casas**

### **Datos de Entrenamiento**
| Tama√±o ($x$) | Precio ($y$) |
|--------------|--------------|
| 40 m¬≤        | 100\$         |
| 60 m¬≤        | 150\$         |
| 80 m¬≤        | 200\$         |

### **Paso 1: Inicializar Par√°metros**  
$$ \theta_0 = 0, \quad \theta_1 = 0 $$

### **Paso 2: Calcular Predicciones Iniciales**  
$$ h_\theta(40) = 0, \quad h_\theta(60) = 0, \quad h_\theta(80) = 0 $$

### **Paso 3: Calcular Funci√≥n de Costo Inicial**  
$$ J = \frac{1}{6} \left[ (-100)^2 + (-150)^2 + (-200)^2 \right] \approx 12,083.33 $$

### **Paso 4: Calcular Derivadas Parciales**  

- $\frac{\partial}{\partial \theta_0} J = \frac{-450}{3} = -150$  
- $\frac{\partial}{\partial \theta_1} J = \frac{-29,000}{3} \approx -9,666.67$  

---

### **Paso 5: Actualizar Par√°metros ($\alpha = 0.0001$)**  

**Aplicaci√≥n detallada de $\alpha$:**  
1. **Para $\theta_0$:**  
   $$ \theta_0 := \theta_0 - \alpha \cdot \frac{\partial}{\partial \theta_0} J $$  
   $$ \theta_0 := 0 - 0.0001 \cdot (-150) = 0 + 0.015 = 0.015 $$  

2. **Para $\theta_1$:**  
   $$ \theta_1 := \theta_1 - \alpha \cdot \frac{\partial}{\partial \theta_1} J $$  
   $$ \theta_1 := 0 - 0.0001 \cdot (-9,666.67) \approx 0 + 0.9667 = 0.9667 $$  

**¬øPor qu√© se suma?**  
- Las derivadas son negativas (error alto), y al multiplicar por $\alpha$ y restar, se convierte en una suma:  
  $$ \theta_j := \theta_j - (\text{valor negativo}) = \theta_j + (\text{valor positivo}) $$  

---

### **Paso 6: Nueva Predicci√≥n**  
$$ h_\theta(40) = 0.015 + 0.9667 \times 40 \approx 38.68\$ $$  
**Nuevo error:** $$ J \approx 10,200.5 $$ *(¬°Error reducido en un 15%!)*  

---

## ‚ùì **¬øPor qu√© Inicializar en $\theta_0 = 0$ y $\theta_1 = 0$?**  

1. **Simplicidad:** Facilita c√°lculos manuales y explicaciones pedag√≥gicas.  
2. **Neutralidad:** Evita sesgos iniciales en el modelo.  
3. **Claridad Visual:** Muestra c√≥mo el gradiente descendente corrige el error desde cero.  

---

## üìâ **Convergencia del Modelo**

- **Graficar $J$ vs. Iteraciones:** Si la curva se estabiliza, el modelo ha convergido.  
- **Tolerancia:** Detener el algoritmo si $\Delta J < 0.001$.  

---

## üí° **Consejos Clave**  

1. **Normalizar datos:** Escala $x$ e $y$ si est√°n en rangos muy diferentes.  
2. **Ajustar $\alpha$:**  
   - **$\alpha$ grande (ej: $0.1$):** Riesgo de divergencia.  
   - **$\alpha$ peque√±o (ej: $0.000001$):** Entrenamiento lento.  
   - **Valor √≥ptimo:** Prueba $0.001$, $0.01$, $0.1$.  
3. **Verificar derivadas:** Usa ejemplos peque√±os para validar c√°lculos.  


#machinelearning #linealregression #lm 
